{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fca23c4",
   "metadata": {},
   "source": [
    "# Telco Classification Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d161e50a",
   "metadata": {},
   "source": [
    "![](telco_churn_pic.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42ad4b63",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-7591692cde2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mprepare_telco\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclean_telco\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_unwanted_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_validate_test_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_distributions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhelper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msplitting_target_var\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdata_dictionary\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/CodeUp-Datascience/telco_classification_project/data_dictionary.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 ],\n\u001b[1;32m     29\u001b[0m     'Dataype' : [\n\u001b[0;32m---> 30\u001b[0;31m                 \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'customer_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m                  \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gender'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                  \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'senior_citizen'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from pydataset import data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import os\n",
    "\n",
    "import graphviz\n",
    "from graphviz import Graph\n",
    "\n",
    "import env\n",
    "from acquire_telco import get_telco_data\n",
    "from prepare_telco import clean_telco, remove_unwanted_values, train_validate_test_split, num_distributions\n",
    "from helper import splitting_target_var\n",
    "from data_dictionary import data_dict\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdc32e9",
   "metadata": {},
   "source": [
    "## Planning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f86a58",
   "metadata": {},
   "source": [
    "- Make a README.md that will hold all of the project details including a data dictionary, key finding, initial hypotheses, and explain how my process can be replicated\n",
    "- Create a MVP, originally and work through the iterative process of making improvements to that MVP.\n",
    "- Define atleast 2 clear sets of null and alternative hypotheses set an alpha value.\n",
    "- Create two .py scripts for both acquire and prepare, in order to automate the collection and cleaning of the data.\n",
    "- Create a helper.py for any other functions I need implamented thoughout the pipeline.\n",
    "- Properly anotate my code as I run though the process, in order for the code to be easily understood, and document any decisions that were made when cleaning, creating new columns, or removing rows of data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19813d56",
   "metadata": {},
   "source": [
    "### Data Science Pipeline\n",
    "##### Acquire\n",
    "- Create an acquire.py (acquire_telco.py) was the name of my py file.\n",
    "- Use that acquire_telco.py file to grab the data from the CodeUp SQL database and cache that file to a csv for ease of accessability.\n",
    "- Render the csv into a pandas dataframe on python.\n",
    "- Summarize the initial data and plot the distributions of individual variables.\n",
    "##### Prepare\n",
    "- Create a prepare.py (prepare_telco.py) was the name of my py file.\n",
    "- Clean the data as I see fit, handling the missing values and encoding values as necessary in order to give numeric values that will work with the models\n",
    "- There were 11 values with no current tenure, and I made the decision to remove those values. These customers have not payed their first bill, so there is no data on weather they are satisfied with the product.\n",
    "- Add new columns that might be useful in modeling, might need more information from the explore for incite into columns that once combined will drive churn.\n",
    "- I added two new columns (auto_pay - if payment type was automatic.),and (add_ons - A column that sums the six aditional services.)\n",
    "##### Explore\n",
    "- Awnser my initial hypotheses that was asked in my planning phase, and test those hypotheses using statistical tests, either accepting or rejecting the null hypothesis.\n",
    "- Continue using statistical testing and visualizations to discover variable relationships in the data, and attempt to understand \"how the data works\".\n",
    "- Summarize my conclusions giving clear awnsers to the questions I posed in the planning stage and summarize any takeaways that might be useful.\n",
    "##### Modeling and Evaluation\n",
    "- Train and evaluate multiple models comparing those models on different evaluation metrics.\n",
    "- Validate the models and choose the best model that was found in the validation phase.\n",
    "- Test the best model found and summarize the performance and document the results using a confusion matrix, predict methods, and classification reports.\n",
    "- Save the test predictions to a .csv file.\n",
    "##### Delivery\n",
    "- Deliver my refined jupyter notebook to the CodeUp data science team.\n",
    "- Summarize my findings, and build a narrative around the data, pulling from my knowledge on story telling.\n",
    "- Walk though the notebook explaining finding, documentation, and decisions that were made.\n",
    "- End with key takeaways and reccomendations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9866539",
   "metadata": {},
   "source": [
    "### EXECUTIVE SUMMARY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ad259c",
   "metadata": {},
   "source": [
    "- \n",
    "- \n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1fb612",
   "metadata": {},
   "source": [
    "### Data Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d2538b",
   "metadata": {},
   "source": [
    "|Target|Datatype|Definition|\n",
    "|:-------|:--------|:----------|\n",
    "| species | 150 non-null: object | iris species - virginica, versicolor, setosa |\n",
    "\n",
    "|Feature|Datatype|Definition|\n",
    "|:-------|:--------|:----------|\n",
    "| petal_length       | 150 non-null: float64 |    iris petal length in cm |\n",
    "| petal_width        | 150 non-null: float64 |    iris petal width in cm |\n",
    "| sepal_length       | 150 non-null: float64 |    iris sepal length in cm |\n",
    "| sepal_width        | 150 non-null: float64 |    iris sepal width in cm |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd2c192f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-8552879b8def>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 ],\n\u001b[1;32m     29\u001b[0m     'Dataype' : [\n\u001b[0;32m---> 30\u001b[0;31m                 \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'customer_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m                  \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gender'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                  \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'senior_citizen'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "ictionary = {\n",
    "    'Feature' : [\n",
    "                'customer_id', \n",
    "                 'gender', \n",
    "                 'senior_citizen', \n",
    "                 'partner', \n",
    "                 'dependents', \n",
    "                 'tenure', \n",
    "                 'phone_service', \n",
    "                 'multiple_lines', \n",
    "                 'internet_service_type_id', \n",
    "                'online_security', \n",
    "                'online_backup', \n",
    "                'device_protection',\n",
    "                'tech_support', \n",
    "                'streaming_tv', \n",
    "                'streaming_movies', \n",
    "                'contract_type_id', \n",
    "                'paperless_billing', \n",
    "                'payment_type_id', \n",
    "                'monthly_charges',\n",
    "                'total_charges',\n",
    "                'churn',\n",
    "                'contract_type',\n",
    "                'internet_service_type',\n",
    "                'payment_type',\n",
    "                'has_churned'\n",
    "                ],\n",
    "    'Dataype' : [\n",
    "                df.dtypes['customer_id'], \n",
    "                 df.dtypes['gender'], \n",
    "                 df.dtypes['senior_citizen'],\n",
    "                df.dtypes['partner'],\n",
    "                 df.dtypes['dependents'], \n",
    "                 df.dtypes['tenure'], \n",
    "                 df.dtypes['phone_service'], \n",
    "                df.dtypes['multiple_lines'],\n",
    "                 df.dtypes['internet_service_type_id'], \n",
    "                df.dtypes['online_security'], \n",
    "                df.dtypes['online_backup'], \n",
    "                df.dtypes['device_protection'],\n",
    "                df.dtypes['tech_support'], \n",
    "                df.dtypes['streaming_tv'], \n",
    "                df.dtypes['streaming_movies'],\n",
    "                df.dtypes['contract_type_id'], \n",
    "                df.dtypes['paperless_billing'], \n",
    "                df.dtypes['payment_type_id'], \n",
    "                df.dtypes['monthly_charges'],\n",
    "                df.dtypes['total_charges'],\n",
    "                df.dtypes['churn'],\n",
    "                df.dtypes['contract_type'],\n",
    "                df.dtypes['internet_service_type'],\n",
    "                df.dtypes['payment_type'],\n",
    "                df.dtypes['has_churned']\n",
    "                ],\n",
    "    'Definition' : ['Identification number for customer', \n",
    "                    'Customer gender, male or female', \n",
    "                    'Yes or no, is the customer a senior citizen', \n",
    "                    'Yes or no, does the customer customer has a parter', \n",
    "                    'Number of dependents a customer has', \n",
    "                    'Number of days a customer has been with the company', \n",
    "                    'Type of phone service plan a customer has', \n",
    "                    'Yes or no, does the customer have multiple lines', \n",
    "                    '1 for DSL, 2 for Fiber Optic, 3 for None', \n",
    "                    'Yes, no, or no internet service',\n",
    "                    'Yes, no, or no internet service', \n",
    "                    'Yes, no, or no internet service',\n",
    "                    'Yes, no, or no internet service', \n",
    "                    'Yes, no, or no internet service',\n",
    "                    'Yes, no, or no internet service',\n",
    "                    '1 for month-to-month, 2 for year, and 3 for two-year contract', \n",
    "                    'Yes or no, whether or not the customer uses paperless billing', \n",
    "                    '1 for electronic check, 2 for mailed check, 3 for automatic bank transfer, 4 for automatic credit card payment',\n",
    "                    'Monthly charges the customer pays',\n",
    "                    'Total charges the customer has paid',\n",
    "                    'Yes or no, whether or not the customer has churned',\n",
    "                    'Month-to-month, year, or two-year contract',\n",
    "                    'DSL, Fiber Optic, or None',\n",
    "                    'Electronic check, mailed check, automatic bank transfer, or automatic credit card payment',\n",
    "                    '0 for has not churned, 1 for has churned'\n",
    "                    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19464bd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a21656",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
